{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python files that contains 'sklearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bigquery_python_framework.GithubPython import GithubPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 43629 files containing 'sklearn'\n"
     ]
    }
   ],
   "source": [
    "sklearnFile = GithubPython().uniqueFiles().contains('sklearn').excludeByRepoName('sklearn').getCount().run()[0][0]\n",
    "print(\"There are {} files containing 'sklearn'\".format(sklearnFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalFile = GithubPython().uniqueFiles().getCount().run()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5995653 files in total\n"
     ]
    }
   ],
   "source": [
    "print('There are {} files in total'.format(totalFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage: 0.727677%\n"
     ]
    }
   ],
   "source": [
    "print('Percentage: %f%%'%(sklearnFile/totalFile*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules that import most 'sklearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moduleImportMostSklearn = GithubPython().module_with_most_import()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('seckcoder/lang-learn', 121),\n",
       " ('magic2du/contact_matrix', 96),\n",
       " ('jpzk/evopy', 87),\n",
       " ('GbalsaC/bitnamiP', 71),\n",
       " ('loli/sklearn-ensembletrees', 61),\n",
       " ('chaluemwut/fbserver', 57),\n",
       " ('zooniverse/aggregation', 51),\n",
       " ('B3AU/waveTree', 49),\n",
       " ('valexandersaulys/airbnb_kaggle_contest', 47),\n",
       " ('kedz/cuttsum', 47),\n",
       " ('Tjorriemorrie/trading', 47),\n",
       " ('southpaw94/MachineLearning', 47),\n",
       " ('akhilpm/Masters-Project', 46),\n",
       " ('salma1601/nilearn', 45),\n",
       " ('diogo149/CauseEffectPairsPaper', 42),\n",
       " ('NicovincX2/Python-3.5', 38),\n",
       " ('chemelnucfin/tensorflow', 37),\n",
       " ('abenicho/isvr', 37),\n",
       " ('ainafp/nilearn', 37),\n",
       " ('weissercn/MLTools', 37)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moduleImportMostSklearn[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printContext(fileName = 'RFC.csv', num = 10):\n",
    "    import csv\n",
    "    with open('context/{}'.format(fileName),'r') as f:\n",
    "        spamreader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        i = 0\n",
    "        for row in spamreader:\n",
    "            if i < 2:\n",
    "                i += 1\n",
    "                continue\n",
    "            if i >= num + 2:\n",
    "                break\n",
    "            print(row[0])\n",
    "            print('\\n------------------------------Separator------------------------------\\n')\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "\n",
      "# classification models\n",
      "classifiers = {'K-Nearest Neighbors (Braycurtis norm)':\n",
      "               KNeighborsClassifier(n_neighbors=3, algorithm='auto',\n",
      "                                    metric='braycurtis'),\n",
      "               'Random Forest':\n",
      "               RandomForestClassifier(n_estimators=80, n_jobs=1),\n",
      "               'SVM': SVC(gamma=2, C=1),\n",
      "               'Linear Support Vector Machine': SVC(kernel=\"linear\", C=0.025),\n",
      "               'Decision Tree': DecisionTreeClassifier(max_depth=5),\n",
      "               'Ada Boost': AdaBoostClassifier(n_estimators=80,\n",
      "                                               learning_rate=0.4),\n",
      "               'Naive Bayes': GaussianNB(),\n",
      "               }\n",
      "vc = VotingClassifier(estimators=list(classifiers.items()), voting='hard')\n",
      "\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "classifers_dict = {'AdaBoost': AdaBoostClassifier(n_estimators=50,\n",
      "                                                  learning_rate=1),\n",
      "                    'Random Forest': RandomForestClassifier(n_estimators=10,\n",
      "                                                            # max_depth=None,\n",
      "                                                            min_samples_split=50,\n",
      "                                                            random_state=0),\n",
      "                    'Naive Bayes': GaussianNB(),\n",
      "                    'SVM': SVC(C=1.5, kernel='poly', degree=2, gamma=0.),\n",
      "                    'Tree': DecisionTreeClassifier(),\n",
      "                    'KNN': KNeighborsClassifier(n_neighbors=22)\n",
      "                    }\n",
      "                    \n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    # train_data = train_data[train_data['Credit_History'] == 1.0]\n",
      "    # print train_data['Month_Pay'].value_counts()\n",
      "\n",
      "    baseline_prediction = train_data.apply(classify, axis=1)\n",
      "    baseline_score = metrics.accuracy_score(baseline_prediction, train_data['Loan_Status'])\n",
      "    print \"Baseline: {:.3f}%\".format(baseline_score*100)\n",
      "    print confusion_matrix(train_data['Loan_Status'], baseline_prediction)\n",
      "\n",
      "    # model = LogisticRegression(C=1, class_weight='balanced')\n",
      "    # model = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5)\n",
      "    # model = RandomForestClassifier(n_estimators=100)\n",
      "    # model = MLPClassifier(algorithm='l-bfgs', alpha=1e-5, hidden_layer_sizes=(10, 3), random_state=1)\n",
      "    # model = RandomForestClassifier(n_estimators=25, min_samples_split=25, max_depth=7, max_features=1)\n",
      "    # model = SVC(C= 1.0, kernel= 'rbf', class_weight={'Y': 4, 'N':1})\n",
      "    # model = SGDClassifier(class_weight='balanced')\n",
      "    # model = GaussianNB()\n",
      "\n",
      "    # params = {'n_estimators': 100, 'max_depth': 5, 'subsample': 0.5,\n",
      "    #       'learning_rate': 0.01, 'min_samples_leaf': 1, 'random_state': 3}\n",
      "    # model = ensemble.GradientBoostingClassifier(**params)\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "from sklearn.metrics import f1_score\n",
      "from sklearn.metrics import precision_score\n",
      "from sklearn.metrics import recall_score\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "import numpy as np\n",
      "\n",
      "from skml.problem_transformation import LabelPowerset\n",
      "from skml.datasets import load_dataset\n",
      "\n",
      "X, y = load_dataset('yeast')\n",
      "clf = LabelPowerset(RandomForestClassifier())\n",
      "clf.fit(X, np.array(y))\n",
      "y_pred = clf.predict(X)\n",
      "\n",
      "print(\"real: \", y.shape)\n",
      "print(\"y_pred: \", y_pred.shape)\n",
      "\n",
      "print(\"hamming loss: \")\n",
      "print(hamming_loss(y, y_pred))\n",
      "\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "df = pd.read_csv(\"parsed.csv\")\n",
      "y1 = df[\"admission_type_id\"].values\n",
      "y2 = df[\"discharge_disposition_id\"].values\n",
      "columns = list(df)[1:4] + list(df)[8:49]\n",
      "print columns\n",
      "X = df[columns].values\n",
      "      \n",
      "X1_train, X1_test, y1_train, y1_test = train_test_split(X, y1, test_size = 0.20)\n",
      "X2_train, X2_test, y2_train, y2_test = train_test_split(X, y2, test_size = 0.20)\n",
      "\n",
      "clf1 = RandomForestClassifier()\n",
      "clf2 = RandomForestClassifier()\n",
      "\n",
      "clf1.fit(X1_train, y1_train)\n",
      "clf2.fit(X2_train, y2_train)\n",
      "y1_pred = clf1.predict(X1_test)\n",
      "y2_pred = clf2.predict(X2_test)\n",
      "\n",
      "acc1 = accuracy_score(y1_test, y1_pred)\n",
      "acc2 = accuracy_score(y2_test, y2_pred)\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    count_enrollment = df_sub['3COURSEID'].value_counts()\n",
      "    #print \"Number of %s enrollment: %s\"%(subject,count_enrollment)\n",
      "\n",
      "    A = df_sub.as_matrix()\n",
      "    X = A[:,4:]\n",
      "    X = X.astype(np.int64, copy=False)\n",
      "    y = A[:,2]\n",
      "    y = y.astype(np.int64, copy=False)\n",
      "\n",
      "    #Training data\n",
      "    forest = RandomForestClassifier(n_estimators=10, max_depth=None, \n",
      "            min_samples_split=1, random_state=None, max_features=None)\n",
      "    clf = forest.fit(X, y)\n",
      "    scores = cross_val_score(clf, X, y, cv=5)\n",
      "    print scores\n",
      "    print \"Random Forest Cross Validation of %s: %s\"%(subject,scores.mean())\n",
      "    precision_rf[subject] = scores.mean()\n",
      "    df_precision.loc[subject]=precision_rf[subject]\n",
      "    print \"-----------------------------------\"\n",
      "    \n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "\n",
      "    plt.xlabel('Relative Importance')\n",
      "    plt.title('%s: Top Features' %(dataName))\n",
      "    plt.grid('off')\n",
      "    plt.ion()\n",
      "    plt.show()\n",
      "    plt.savefig(str(dataName)+'TopFeatures.png',dpi=200)\n",
      "\n",
      "def altPlotFeaturesImportance(X,y,featureNames,dataName):\n",
      "    \"http://nbviewer.ipython.org/github/cs109/2014/blob/master/homework-solutions/HW5-solutions.ipynb\"\n",
      "    clf = RandomForestClassifier(n_estimators=50)\n",
      "\n",
      "    clf.fit(X,y)\n",
      "    importance_list = clf.feature_importances_\n",
      "    # name_list = df.columns #ORIG\n",
      "    name_list=featureNames\n",
      "\n",
      "    importance_list, name_list = zip(*sorted(zip(importance_list, name_list)))\n",
      "    plt.barh(range(len(name_list)),importance_list,align='center')\n",
      "    plt.yticks(range(len(name_list)),name_list)\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "# strings.\n",
      "train_data_features = vectorizer.fit_transform(train_data).toarray()\n",
      "\n",
      "print(train_data_features.shape)\n",
      "\n",
      "\n",
      "#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
      "\n",
      "# Initialize a Random Forest classifier with trees\n",
      "# use as many CPU cores as possible (n_jobs=-1)\n",
      "forest = RandomForestClassifier(n_estimators = 1000, n_jobs=-1, verbose=2) \n",
      "\n",
      "# Fit the forest to the training set, using the bag of words as \n",
      "# features and the sentiment labels as the response variable\n",
      "#\n",
      "# This may take a few minutes to run\n",
      "forest = forest.fit(train_data_features, train[\"sponsored\"])\n",
      "\n",
      "\n",
      "#Run the prediction...\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    y2 += [dep(test)]\n",
      "  return x1,y1,x2,y2\n",
      "\n",
      "def learns(tests,trains,indep=lambda x: x[:-1],\n",
      "                    dep = lambda x: x[-1],\n",
      "                    rf  = Abcd(),\n",
      "                    lg  = Abcd(),\n",
      "                    dt  = Abcd(),\n",
      "                    nb  = Abcd()):\n",
      "  x1,y1,x2,y2= trainTest(tests,trains,indep,dep) \n",
      "  forest = RandomForestClassifier(n_estimators = 50)  \n",
      "  forest = forest.fit(x1,y1)\n",
      "  for n,got in enumerate(forest.predict(x2)):\n",
      "    rf(predicted = got, actual = y2[n])\n",
      "  logreg = linear_model.LogisticRegression(C=1e5)\n",
      "  logreg.fit(x1, y1)\n",
      "  for n,got in enumerate(logreg.predict(x2)):\n",
      "    lg(predicted = got, actual = y2[n])\n",
      "  bayes =  GaussianNB()\n",
      "  bayes.fit(x1,y1)\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    :param selectKBest: The number of best features to select\n",
      "    :type selectKBest: int\n",
      "    :param kfold: The number of folds to use in K-fold CV\n",
      "    :type kfold: int\n",
      "    :return: A list of predicted labels across the k-folds\n",
      "    \"\"\"\n",
      "    try:\n",
      "        # Prepare data\n",
      "        X, y = numpy.array(X), numpy.array(y)\n",
      "        # Define classifier\n",
      "        clf = ensemble.RandomForestClassifier(n_estimators=estimators, criterion=criterion, max_depth=maxdepth)\n",
      "        if selectKBest > 0:\n",
      "            X_new = SelectKBest(chi2, k=selectKBest).fit_transform(X, y)\n",
      "            predicted = cross_val_predict(clf, X_new, y, cv=kfold).tolist()\n",
      "        else:\n",
      "            predicted = cross_val_predict(clf, X, y, cv=kfold).tolist()\n",
      "    except Exception as e:\n",
      "        prettyPrintError(e)\n",
      "        return []\n",
      "\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseEstimator + @deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queryString = \"\"\"\\\n",
    "SELECT\n",
    "  FIRST(sample_repo_name),\n",
    "  sample_path,\n",
    "FROM \n",
    "  [scikit-learn-research:pyfiles.content_py] \n",
    "WHERE\n",
    "  content CONTAINS 'BaseEstimator'\n",
    "  AND content CONTAINS '@deprecated'\n",
    "  AND (NOT RIGHT(sample_repo_name,12) = \"scikit-learn\")\n",
    "  AND (NOT RIGHT(sample_repo_name,7) = \"sklearn\")\n",
    "  AND (NOT sample_path CONTAINS 'sklearn')\n",
    "  AND (NOT sample_path CONTAINS 'scikit-learn')\n",
    "GROUP BY 2\n",
    "\"\"\"\n",
    "baseEstimatorDeprecated = GithubPython()\n",
    "result = baseEstimatorDeprecated.run(queryString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getGithubURL(result):\n",
    "    for repo_name, path in result:\n",
    "        print(\"https://github.com/{}/tree/master/{}\".format(repo_name,path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seen = []\n",
    "resultFiltered = []\n",
    "for repo, path in result:\n",
    "    if \"/\".join(path.split(\"/\")[-3:]) not in seen:\n",
    "        resultFiltered.append([repo,path])\n",
    "        seen.append(\"/\".join(path.split(\"/\")[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/AsimmHirani/ISpyPi/tree/master/tensorflow/contrib/tensorflow-master/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py\n",
      "https://github.com/mengxn/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/estimators/estimator.py\n",
      "https://github.com/Denisolt/Tensorflow_Chat_Bot/tree/master/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/utils/export.py\n",
      "https://github.com/liyi193328/seq2seq/tree/master/seq2seq/contrib/monitors.py\n",
      "https://github.com/psarka/uplift/tree/master/uplift/base.py\n",
      "https://github.com/Bismarrck/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/estimators/linear.py\n",
      "https://github.com/AsimmHirani/ISpyPi/tree/master/tensorflow/contrib/tensorflow-master/tensorflow/contrib/learn/python/learn/estimators/dnn.py\n",
      "https://github.com/pierreg/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/estimators/svm.py\n",
      "https://github.com/liyi193328/seq2seq/tree/master/seq2seq/contrib/estimator.py\n",
      "https://github.com/zhonghualiu/FaST-LMM/tree/master/fastlmm/external/pca.py\n",
      "https://github.com/JosmanPS/parallel-SVM/tree/master/m_learning/svm/base.py\n",
      "https://github.com/dlatk/dlatk/tree/master/dlatk/pca_mod.py\n",
      "https://github.com/bmcfee/librosa/tree/master/librosa/util/feature_extractor.py\n",
      "https://github.com/Astroua/SCIMES/tree/master/scimes/spectral.py\n",
      "https://github.com/Denisolt/Tensorflow_Chat_Bot/tree/master/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py\n",
      "https://github.com/tongwang01/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/estimators/random_forest.py\n",
      "https://github.com/Sklearn-HMM/scikit-learn-HMM/tree/master/sklean-hmm/linear_model/stochastic_gradient.py\n",
      "https://github.com/alexandrebarachant/mne-python/tree/master/mne/decoding/transformer.py\n",
      "https://github.com/haribharadwaj/mne-python/tree/master/mne/decoding/time_gen.py\n",
      "https://github.com/dwettstein/pattern-recognition-2016/tree/master/mlp/gaussian_process/gaussian_process.py\n",
      "https://github.com/psarka/uplift/tree/master/uplift/preprocessing/data.py\n",
      "https://github.com/hubertjb/mne-python/tree/master/mne/decoding/base.py\n",
      "https://github.com/psarka/uplift/tree/master/uplift/tests/test_base.py\n"
     ]
    }
   ],
   "source": [
    "getGithubURL(resultFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23 files with BaseEstimator + @deprecated\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} files with BaseEstimator + @deprecated\".format(len(resultFiltered)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context of @deprecated in above files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getContext(modelName):\n",
    "  from google.cloud import bigquery\n",
    "  client = bigquery.Client()\n",
    "  query = '''\\\n",
    "  #standardSQL\n",
    "  CREATE TEMPORARY FUNCTION parsePythonFile(a STRING)\n",
    "  RETURNS STRING\n",
    "  LANGUAGE js AS \"\"\"\n",
    "    if (a === null) {\n",
    "      return null;\n",
    "    }\n",
    "    var lines = a.split('\\\\\\\\n');\n",
    "    for (i=0;i<lines.length;i++) {\n",
    "      if (lines[i].indexOf(\"%s\")!==-1){\n",
    "        return lines.slice(Math.max(i-10,0),Math.min(i+10,lines.length-1)).join(\"\\\\\\\\n\");\n",
    "      }\n",
    "    }\n",
    "  \"\"\";\n",
    "\n",
    "  CREATE TEMPORARY FUNCTION parsePythonFile2(a STRING, b STRING)\n",
    "  RETURNS STRING\n",
    "  LANGUAGE js AS \"\"\"\n",
    "    if (a === null) {\n",
    "      return null;\n",
    "    }\n",
    "    var lines = a.split('\\\\\\\\n');\n",
    "    for (i=0;i<lines.length;i++) {\n",
    "      if (lines[i].indexOf(\"%s\")!==-1){\n",
    "        return b;\n",
    "      }\n",
    "    }\n",
    "  \"\"\";\n",
    "\n",
    "  SELECT\n",
    "    parsePythonFile(content) match,\n",
    "    parsePythonFile2(content,sample_path) path,\n",
    "    parsePythonFile2(content,sample_repo_name ) repo_name,\n",
    "    count(*) count\n",
    "  FROM   \n",
    "    `scikit-learn-research.pyfiles.content_py` \n",
    "  WHERE\n",
    "    (NOT ENDS_WITH(sample_repo_name, \"scikit-learn\"))\n",
    "     AND (NOT ENDS_WITH(sample_repo_name, \"sklearn\"))\n",
    "     AND NOT STRPOS(content,'BaseEstimator') = 0\n",
    "     AND STRPOS(sample_path,'sklearn') = 0\n",
    "     AND STRPOS(sample_path,'scikit-learn') = 0\n",
    "  GROUP BY\n",
    "  1,2,3\n",
    "  ORDER BY \n",
    "  count DESC\n",
    "  '''% (modelName,modelName)\n",
    "  result = client.run_sync_query(query)\n",
    "  result.timeout_ms = 99999999\n",
    "  result.run()\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultForContext = getContext('@deprecated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultForContext = resultForContext.rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    if self._n_classes == 2:\n",
      "      metrics.update({\n",
      "          \"auc\": metric_spec.MetricSpec(\n",
      "              metric_fn=metrics_lib.streaming_auc,\n",
      "              prediction_key=_LOGISTIC,\n",
      "              weight_key=self._weight_column_name)})\n",
      "    return self._estimator.evaluate(\n",
      "        x=x, y=y, input_fn=input_fn, feed_fn=feed_fn, batch_size=batch_size,\n",
      "        steps=steps, metrics=metrics, name=name)\n",
      "\n",
      "  @deprecated_arg_values(\n",
      "      estimator.AS_ITERABLE_DATE, estimator.AS_ITERABLE_INSTRUCTIONS,\n",
      "      as_iterable=False)\n",
      "  def predict(self, x=None, input_fn=None, batch_size=None, as_iterable=False):\n",
      "    \"\"\"Returns predicted classes for given features.\n",
      "\n",
      "    Args:\n",
      "      x: features.\n",
      "      input_fn: Input function. If set, x must be None.\n",
      "      batch_size: Override default batch size.\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "          matched.append(key)\n",
      "    return matched, non_matched\n",
      "\n",
      "\n",
      "class ExportMonitor(EveryN):\n",
      "  \"\"\"Monitor that exports Estimator every N steps.\"\"\"\n",
      "\n",
      "  # TODO(philstahlfeld): Investigate switching export.export_estimator\n",
      "  # configuration values to **kwargs so that updates to the export_estimator\n",
      "  # function don't have to be reflected here.\n",
      "  @deprecated_arg_values(\n",
      "      \"2016-09-23\",\n",
      "      \"The signature of the input_fn accepted by export is changing to be \"\n",
      "      \"consistent with what's used by tf.Learn Estimator's train/evaluate. \"\n",
      "      \"input_fn (and in most cases, input_feature_key) will both become \"\n",
      "      \"required args.\",\n",
      "      input_fn=None)\n",
      "  def __init__(self,\n",
      "               every_n_steps,\n",
      "               export_dir,\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "            \"dnn_optimizer\": dnn_optimizer,\n",
      "            \"dnn_hidden_units\": dnn_hidden_units,\n",
      "            \"dnn_activation_fn\": dnn_activation_fn,\n",
      "            \"dnn_dropout\": dnn_dropout,\n",
      "            \"gradient_clip_norm\": gradient_clip_norm,\n",
      "            \"embedding_lr_multipliers\": embedding_lr_multipliers,\n",
      "            \"input_layer_min_slice_size\": input_layer_min_slice_size,\n",
      "        },\n",
      "        feature_engineering_fn=feature_engineering_fn)\n",
      "\n",
      "  @deprecated_arg_values(\n",
      "      estimator.AS_ITERABLE_DATE, estimator.AS_ITERABLE_INSTRUCTIONS,\n",
      "      as_iterable=False)\n",
      "  @deprecated_arg_values(\n",
      "      \"2017-03-01\",\n",
      "      \"Please switch to predict_classes, or set `outputs` argument.\",\n",
      "      outputs=None)\n",
      "  def predict(self, x=None, input_fn=None, batch_size=None, outputs=None,\n",
      "              as_iterable=True):\n",
      "    \"\"\"Returns predictions for given features.\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "          \"joint_weights\": _joint_weight,\n",
      "      })\n",
      "\n",
      "    super(LinearClassifier, self).__init__(\n",
      "        model_fn=model_fn,\n",
      "        model_dir=model_dir,\n",
      "        config=config,\n",
      "        params=params,\n",
      "        feature_engineering_fn=feature_engineering_fn)\n",
      "\n",
      "  @deprecated_arg_values(\n",
      "      estimator.AS_ITERABLE_DATE, estimator.AS_ITERABLE_INSTRUCTIONS,\n",
      "      as_iterable=False)\n",
      "  @deprecated_arg_values(\n",
      "      \"2017-03-01\",\n",
      "      \"Please switch to predict_classes, or set `outputs` argument.\",\n",
      "      outputs=None)\n",
      "  def predict(self, x=None, input_fn=None, batch_size=None, outputs=None,\n",
      "              as_iterable=True):\n",
      "    \"\"\"Returns predictions for given features.\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "      input_tensor=examples, output_tensor=positive_predictions)\n",
      "  return default_signature, {}\n",
      "\n",
      "\n",
      "# pylint: disable=protected-access\n",
      "def _default_input_fn(estimator, examples):\n",
      "  \"\"\"Creates default input parsing using Estimator's feature signatures.\"\"\"\n",
      "  return estimator._get_feature_ops_from_example(examples)\n",
      "\n",
      "\n",
      "@deprecated('2016-09-23', 'Please use BaseEstimator.export')\n",
      "def export_estimator(estimator,\n",
      "                     export_dir,\n",
      "                     signature_fn=None,\n",
      "                     input_fn=_default_input_fn,\n",
      "                     default_batch_size=1,\n",
      "                     exports_to_keep=None):\n",
      "  \"\"\"Deprecated, please use BaseEstimator.export.\"\"\"\n",
      "  _export_estimator(estimator=estimator,\n",
      "                    export_dir=export_dir,\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "        if value1 != value2:\n",
      "          non_matched[key] = (value1, value2)\n",
      "        else:\n",
      "          matched.append(key)\n",
      "    return matched, non_matched\n",
      "\n",
      "\n",
      "class ExportMonitor(EveryN):\n",
      "  \"\"\"Monitor that exports Estimator every N steps.\"\"\"\n",
      "\n",
      "  @deprecated(\"2017-03-25\",\n",
      "              \"ExportMonitor is deprecated. Please pass an \"\n",
      "              \"ExportStrategy to Experiment instead.\")\n",
      "  def __init__(self,\n",
      "               every_n_steps,\n",
      "               export_dir,\n",
      "               input_fn=None,\n",
      "               input_feature_key=None,\n",
      "               exports_to_keep=5,\n",
      "               signature_fn=None,\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "        'regression_signature_fn or classification_signature_fn_with_prob '\n",
      "        'instead?'.format(predictions_shape[1], predictions_shape))\n",
      "\n",
      "  positive_predictions = predictions_tensor[:, 1]\n",
      "  default_signature = exporter.regression_signature(\n",
      "      input_tensor=examples, output_tensor=positive_predictions)\n",
      "  return default_signature, {}\n",
      "\n",
      "\n",
      "# pylint: disable=protected-access\n",
      "@deprecated(\n",
      "    '2016-09-23',\n",
      "    'The signature of the input_fn accepted by export is changing to be '\n",
      "    'consistent with what\\'s used by tf.Learn Estimator\\'s train/evaluate, '\n",
      "    'which makes this function useless. This will be removed after the '\n",
      "    'deprecation date.')\n",
      "def _default_input_fn(estimator, examples):\n",
      "  \"\"\"Creates default input parsing using Estimator's feature signatures.\"\"\"\n",
      "  return estimator._get_feature_ops_from_example(examples)\n",
      "\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    self.data_feeder = None\n",
      "    self.device_assigner = (\n",
      "        device_assigner or tensor_forest.RandomForestDeviceAssigner())\n",
      "    self.graph_builder_class = graph_builder_class\n",
      "    self.training_args = {}\n",
      "    self.construction_args = {}\n",
      "\n",
      "    super(TensorForestEstimator, self).__init__(model_dir=model_dir,\n",
      "                                                config=config)\n",
      "\n",
      "  @deprecated_arg_values(\n",
      "      estimator.AS_ITERABLE_DATE, estimator.AS_ITERABLE_INSTRUCTIONS,\n",
      "      as_iterable=False)\n",
      "  def predict_proba(\n",
      "      self, x=None, input_fn=None, batch_size=None, as_iterable=False):\n",
      "    \"\"\"Returns prediction probabilities for given features (classification).\n",
      "\n",
      "    Args:\n",
      "      x: features.\n",
      "      input_fn: Input function. If set, x and y must be None.\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "      for each `column` in `dnn_feature_columns` + `linear_feature_columns`:\n",
      "      - if `column` is a `SparseColumn`, a feature with `key=column.name`\n",
      "        whose `value` is a `SparseTensor`.\n",
      "      - if `column` is a `WeightedSparseColumn`, two features: the first with\n",
      "        `key` the id column name, the second with `key` the weight column\n",
      "        name. Both features' `value` must be a `SparseTensor`.\n",
      "      - if `column` is a `RealValuedColumn, a feature with `key=column.name`\n",
      "        whose `value` is a `Tensor`.\n",
      "  \"\"\"\n",
      "\n",
      "  @deprecated_arg_values(\n",
      "      _FIX_GLOBAL_STEP_INCREMENT_DATE,\n",
      "      _FIX_GLOBAL_STEP_INCREMENT_INSTRUCTIONS,\n",
      "      fix_global_step_increment_bug=False)\n",
      "  def __init__(self,  # _joint_linear_weights pylint: disable=invalid-name\n",
      "               head,\n",
      "               model_dir=None,\n",
      "               linear_feature_columns=None,\n",
      "               linear_optimizer=None,\n",
      "               _joint_linear_weights=False,\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "          matched.append(key)\n",
      "    return matched, non_matched\n",
      "\n",
      "\n",
      "class ExportMonitor(EveryN):\n",
      "  \"\"\"Monitor that exports Estimator every N steps.\"\"\"\n",
      "\n",
      "  # TODO(philstahlfeld): Investigate switching export.export_estimator\n",
      "  # configuration values to **kwargs so that updates to the export_estimator\n",
      "  # function don't have to be reflected here.\n",
      "  @deprecated_arg_values(\n",
      "      \"2016-09-23\",\n",
      "      \"The signature of the input_fn accepted by export is changing to be \"\n",
      "      \"consistent with what's used by tf.Learn Estimator's train/evaluate. \"\n",
      "      \"input_fn (and in most cases, input_feature_key) will both become \"\n",
      "      \"required args.\",\n",
      "      input_fn=None)\n",
      "  def __init__(self,\n",
      "               every_n_steps,\n",
      "               export_dir,\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    self._features_info = None\n",
      "    self._labels_info = None\n",
      "\n",
      "    self._graph = None\n",
      "\n",
      "  @property\n",
      "  def config(self):\n",
      "    # TODO(wicke): make RunConfig immutable, and then return it without a copy.\n",
      "    return copy.deepcopy(self._config)\n",
      "\n",
      "  @deprecated_args(\n",
      "      SCIKIT_DECOUPLE_DATE, SCIKIT_DECOUPLE_INSTRUCTIONS, ('x', None),\n",
      "      ('y', None), ('batch_size', None)\n",
      "  )\n",
      "  def fit(self, x=None, y=None, input_fn=None, steps=None, batch_size=None,\n",
      "          monitors=None, max_steps=None):\n",
      "    # pylint: disable=g-doc-args,g-doc-return-or-yield\n",
      "    \"\"\"See `Trainable`.\n",
      "\n",
      "    Raises:\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "      for each `column` in `dnn_feature_columns` + `linear_feature_columns`:\n",
      "      - if `column` is a `SparseColumn`, a feature with `key=column.name`\n",
      "        whose `value` is a `SparseTensor`.\n",
      "      - if `column` is a `WeightedSparseColumn`, two features: the first with\n",
      "        `key` the id column name, the second with `key` the weight column\n",
      "        name. Both features' `value` must be a `SparseTensor`.\n",
      "      - if `column` is a `RealValuedColumn, a feature with `key=column.name`\n",
      "        whose `value` is a `Tensor`.\n",
      "  \"\"\"\n",
      "\n",
      "  @deprecated_arg_values(\n",
      "      _FIX_GLOBAL_STEP_INCREMENT_DATE,\n",
      "      _FIX_GLOBAL_STEP_INCREMENT_INSTRUCTIONS,\n",
      "      fix_global_step_increment_bug=False)\n",
      "  def __init__(self,  # _joint_linear_weights pylint: disable=invalid-name\n",
      "               head,\n",
      "               model_dir=None,\n",
      "               linear_feature_columns=None,\n",
      "               linear_optimizer=None,\n",
      "               _joint_linear_weights=False,\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    self._features_info = {}\n",
      "    self._labels_info = {}\n",
      "\n",
      "    self._graph = None\n",
      "\n",
      "  @property\n",
      "  def config(self):\n",
      "    # TODO(wicke): make RunConfig immutable, and then return it without a copy.\n",
      "    return copy.deepcopy(self._config)\n",
      "\n",
      "  @deprecated_args(\n",
      "      SCIKIT_DECOUPLE_DATE, SCIKIT_DECOUPLE_INSTRUCTIONS, 'x', 'y', 'batch_size'\n",
      "  )\n",
      "  def fit(self, x=None, y=None, input_fn=None, steps=None, batch_size=None,\n",
      "          monitors=None, max_steps=None):\n",
      "    # pylint: disable=g-doc-args,g-doc-return-or-yield\n",
      "    \"\"\"See `Trainable`.\n",
      "\n",
      "    Raises:\n",
      "      ValueError: If `x` or `y` are not `None` while `input_fn` is not `None`.\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "          \"joint_weights\": _joint_weight,\n",
      "      })\n",
      "\n",
      "    super(LinearClassifier, self).__init__(\n",
      "        model_fn=model_fn,\n",
      "        model_dir=model_dir,\n",
      "        config=config,\n",
      "        params=params,\n",
      "        feature_engineering_fn=feature_engineering_fn)\n",
      "\n",
      "  @deprecated_arg_values(\n",
      "      estimator.AS_ITERABLE_DATE, estimator.AS_ITERABLE_INSTRUCTIONS,\n",
      "      as_iterable=False)\n",
      "  @deprecated_arg_values(\n",
      "      \"2017-03-01\",\n",
      "      \"Please switch to predict_classes, or set `outputs` argument.\",\n",
      "      outputs=None)\n",
      "  def predict(self, x=None, input_fn=None, batch_size=None, outputs=None,\n",
      "              as_iterable=True):\n",
      "    \"\"\"Returns predictions for given features.\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    self._features_info = None\n",
      "    self._labels_info = None\n",
      "\n",
      "    self._graph = None\n",
      "\n",
      "  @property\n",
      "  def config(self):\n",
      "    # TODO(wicke): make RunConfig immutable, and then return it without a copy.\n",
      "    return copy.deepcopy(self._config)\n",
      "\n",
      "  @deprecated_args(\n",
      "      SCIKIT_DECOUPLE_DATE, SCIKIT_DECOUPLE_INSTRUCTIONS, ('x', None),\n",
      "      ('y', None), ('batch_size', None)\n",
      "  )\n",
      "  def fit(self, x=None, y=None, input_fn=None, steps=None, batch_size=None,\n",
      "          monitors=None, max_steps=None):\n",
      "    # pylint: disable=g-doc-args,g-doc-return-or-yield\n",
      "    \"\"\"See `Trainable`.\n",
      "\n",
      "    Raises:\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    self._features_info = None\n",
      "    self._labels_info = None\n",
      "\n",
      "    self._graph = None\n",
      "\n",
      "  @property\n",
      "  def config(self):\n",
      "    # TODO(wicke): make RunConfig immutable, and then return it without a copy.\n",
      "    return copy.deepcopy(self._config)\n",
      "\n",
      "  @deprecated_args(\n",
      "      SCIKIT_DECOUPLE_DATE, SCIKIT_DECOUPLE_INSTRUCTIONS, 'x', 'y', 'batch_size'\n",
      "  )\n",
      "  def fit(self, x=None, y=None, input_fn=None, steps=None, batch_size=None,\n",
      "          monitors=None, max_steps=None):\n",
      "    # pylint: disable=g-doc-args,g-doc-return-or-yield\n",
      "    \"\"\"See `Trainable`.\n",
      "\n",
      "    Raises:\n",
      "      ValueError: If `x` or `y` are not `None` while `input_fn` is not `None`.\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "          \"joint_weights\": _joint_weight,\n",
      "      })\n",
      "\n",
      "    super(LinearClassifier, self).__init__(\n",
      "        model_fn=model_fn,\n",
      "        model_dir=model_dir,\n",
      "        config=config,\n",
      "        params=params,\n",
      "        feature_engineering_fn=feature_engineering_fn)\n",
      "\n",
      "  @deprecated_arg_values(\n",
      "      estimator.AS_ITERABLE_DATE, estimator.AS_ITERABLE_INSTRUCTIONS,\n",
      "      as_iterable=False)\n",
      "  def predict(self, x=None, input_fn=None, batch_size=None, as_iterable=True):\n",
      "    \"\"\"Runs inference to determine the predicted class (i.e. class index).\"\"\"\n",
      "    return self.predict_classes(\n",
      "        x=x,\n",
      "        input_fn=input_fn,\n",
      "        batch_size=batch_size,\n",
      "        as_iterable=as_iterable)\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "    return result\n",
      "\n",
      "  # TODO(ispir): Simplify evaluate by aligning this logic with custom Estimator.\n",
      "  def evaluate(self, x=None, y=None, input_fn=None, feed_fn=None,\n",
      "               batch_size=None, steps=None, metrics=None, name=None):\n",
      "    \"\"\"See evaluable.Evaluable.\"\"\"\n",
      "    return self._estimator.evaluate(x=x, y=y, input_fn=input_fn,\n",
      "                                    feed_fn=feed_fn, batch_size=batch_size,\n",
      "                                    steps=steps, metrics=metrics, name=name)\n",
      "\n",
      "  @deprecated_arg_values(\n",
      "      estimator.AS_ITERABLE_DATE, estimator.AS_ITERABLE_INSTRUCTIONS,\n",
      "      as_iterable=False)\n",
      "  def predict(self, x=None, input_fn=None, batch_size=None, as_iterable=True):\n",
      "    \"\"\"Runs inference to determine the predicted class.\"\"\"\n",
      "    preds = self._estimator.predict(x=x, input_fn=input_fn,\n",
      "                                    batch_size=batch_size,\n",
      "                                    outputs=[head_lib.PredictionKey.CLASSES],\n",
      "                                    as_iterable=as_iterable)\n",
      "    if as_iterable:\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n",
      "        'regression_signature_fn instead?'.format(predictions_shape[1],\n",
      "                                                  predictions_shape))\n",
      "\n",
      "  positive_predictions = predictions[:, 1]\n",
      "  default_signature = exporter.regression_signature(\n",
      "      input_tensor=examples, output_tensor=positive_predictions)\n",
      "  return default_signature, {}\n",
      "\n",
      "\n",
      "# pylint: disable=protected-access\n",
      "@deprecated(\n",
      "    '2016-09-23',\n",
      "    'The signature of the input_fn accepted by export is changing to be '\n",
      "    'consistent with what\\'s used by tf.Learn Estimator\\'s train/evaluate, '\n",
      "    'which makes this function useless. This will be removed after the '\n",
      "    'deprecation date.')\n",
      "def _default_input_fn(estimator, examples):\n",
      "  \"\"\"Creates default input parsing using Estimator's feature signatures.\"\"\"\n",
      "  return estimator._get_feature_ops_from_example(examples)\n",
      "\n",
      "\n",
      "------------------------------Separator------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for val, _, _, _ in resultForContext[:20]:\n",
    "    print(val)\n",
    "    print('\\n------------------------------Separator------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about DeprecationWarning + BaseEstimator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "queryStringForDeprecationWarning = \"\"\"\\\n",
    "SELECT\n",
    "  FIRST(sample_repo_name),\n",
    "  sample_path,\n",
    "FROM \n",
    "  [scikit-learn-research:pyfiles.content_py] \n",
    "WHERE\n",
    "  content CONTAINS 'BaseEstimator'\n",
    "  AND content CONTAINS 'DeprecationWarning'\n",
    "  AND (NOT RIGHT(sample_repo_name,12) = \"scikit-learn\")\n",
    "  AND (NOT RIGHT(sample_repo_name,7) = \"sklearn\")\n",
    "  AND (NOT sample_path CONTAINS 'sklearn')\n",
    "  AND (NOT sample_path CONTAINS 'scikit-learn')\n",
    "GROUP BY 2\n",
    "\"\"\"\n",
    "baseEstimatorDeprecated = GithubPython()\n",
    "result = baseEstimatorDeprecated.run(queryStringForDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seen = []\n",
    "resultFiltered = []\n",
    "for repo, path in result:\n",
    "    if \"/\".join(path.split(\"/\")[-3:]) not in seen:\n",
    "        resultFiltered.append([repo,path])\n",
    "        seen.append(\"/\".join(path.split(\"/\")[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/annapasca/mne-python/tree/master/mne/fixes.py\n",
      "https://github.com/ml-slac/deep-jets/tree/master/training/fisher.py\n",
      "https://github.com/rafwiewiora/msmbuilder/tree/master/msmbuilder/tests/test_estimator_subclassing.py\n",
      "https://github.com/msultan/osprey/tree/master/osprey/eval_scopes.py\n",
      "https://github.com/gusseppe/pymach/tree/master/pymach/improve.py\n",
      "https://github.com/cxhernandez/msmbuilder/tree/master/msmbuilder/cluster/__init__.py\n",
      "https://github.com/tgsmith61591/skutil/tree/master/skutil/h2o/split.py\n",
      "https://github.com/Sklearn-HMM/scikit-learn-HMM/tree/master/sklean-hmm/linear_model/stochastic_gradient.py\n",
      "https://github.com/anonymous-ijcai/dsw-ont-ijcai/tree/master/dswont/relation_type.py\n",
      "https://github.com/JosmanPS/parallel-SVM/tree/master/m_learning/base.py\n",
      "https://github.com/dwettstein/pattern-recognition-2016/tree/master/mlp/gaussian_process/gaussian_process.py\n",
      "https://github.com/likelyzhao/mxnet/tree/master/python/mxnet/model.py\n",
      "https://github.com/slipguru/adenine/tree/master/adenine/externals/hierarchical.py\n",
      "https://github.com/chrissly31415/amimanera/tree/master/qsprLib.py\n",
      "https://github.com/Eigenstate/msmbuilder/tree/master/msmbuilder/featurizer/feature_union.py\n",
      "https://github.com/psarka/uplift/tree/master/uplift/utils/testing.py\n",
      "https://github.com/samuelsinayoko/kaggle-housing-prices/tree/master/samlib.py\n",
      "https://github.com/msultan/msmbuilder/tree/master/msmbuilder/dataset.py\n",
      "https://github.com/dlatk/dlatk/tree/master/dlatk/pca_mod.py\n",
      "https://github.com/psarka/uplift/tree/master/uplift/base.py\n",
      "https://github.com/jpopham91/berserker/tree/master/berserker/nodes.py\n",
      "https://github.com/trevorstephens/gplearn/tree/master/gplearn/skutils/testing.py\n",
      "https://github.com/jmetzen/skgp/tree/master/skgp/estimators/gaussian_process.py\n",
      "https://github.com/cle1109/mne-python/tree/master/mne/decoding/base.py\n",
      "https://github.com/thorwhalen/ut/tree/master/ml/feature_extraction/text.py\n",
      "https://github.com/psarka/uplift/tree/master/uplift/preprocessing/data.py\n",
      "https://github.com/psarka/uplift/tree/master/uplift/tests/test_base.py\n",
      "https://github.com/dr-nate/msmbuilder/tree/master/msmbuilder/featurizer/featurizer.py\n",
      "https://github.com/trendelkampschroer/PyEMMA/tree/master/pyemma/_base/model.py\n",
      "https://github.com/chkoar/imbalanced-learn/tree/master/imblearn/base.py\n",
      "https://github.com/ntung/ramp/tree/master/gaussian_process_no_normalization_of_inputs.py\n",
      "https://github.com/JosmanPS/parallel-SVM/tree/master/m_learning/svm/base.py\n",
      "https://github.com/mthomure/glimpse-project/tree/master/glimpse/util/learn/kmeans.py\n",
      "https://github.com/zhonghualiu/FaST-LMM/tree/master/fastlmm/external/pca.py\n",
      "https://github.com/pburdet/hyperspy/tree/master/hyperspy/misc/machine_learning/fastica.py\n",
      "https://github.com/Astroua/SCIMES/tree/master/scimes/spectral.py\n",
      "https://github.com/gusseppe/pymach/tree/master/pymach/evaluate.py\n",
      "https://github.com/wmvanvliet/mne-python/tree/master/mne/decoding/csp.py\n",
      "https://github.com/Sklearn-HMM/scikit-learn-HMM/tree/master/sklean-hmm/naive_bayes.py\n",
      "https://github.com/dwettstein/pattern-recognition-2016/tree/master/mlp/model_selection/_split.py\n",
      "https://github.com/Sklearn-HMM/scikit-learn-HMM/tree/master/sklean-hmm/tree/tree.py\n"
     ]
    }
   ],
   "source": [
    "getGithubURL(resultFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41 files with BaseEstimator + DeprecationWarning\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} files with BaseEstimator + DeprecationWarning\".format(len(resultFiltered)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
